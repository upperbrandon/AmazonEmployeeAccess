library(tidyverse)
library(tidymodels)
library(vroom)
library(skimr)
library(DataExplorer)
library(patchwork)
library(glmnet)
library(ranger)
library(ggmosaic)
library(embed)
# Read and Set ------------------------------------------------------------
setwd("~/GitHub/AmazonEmployeeAccess")
train_data <- vroom("train.csv")
test_data  <- vroom("test.csv")
# Ensure ACTION is a factor -----------------------------------------------
train_data <- train_data %>%
mutate(ACTION = factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train_data) %>%
step_mutate_at(all_numeric_predictors(), fn = as.factor) %>%
step_other(all_nominal_predictors(), threshold = 0.001) %>%
step_embed(all_nominal_predictors(), outcome = vars(ACTION)) %>%  # <-- target encoding
step_zv(all_predictors())  # remove zero-variance columns
# Model Specification: Penalized Logistic Regression ---------------------
logRegModel <- logistic_reg(
penalty = tune(),  # lambda
mixture = tune()   # alpha
) %>%
set_engine("glmnet") %>%
set_mode("classification")
# Workflow ---------------------------------------------------------------
logReg_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel)
# Cross-validation -------------------------------------------------------
set.seed(123)
amazon_folds <- vfold_cv(train_data, v = 5, strata = ACTION)
# Tuning Grid -------------------------------------------------------------
lambda_grid <- grid_regular(
penalty(range = c(-4, 0)),  # log10 scale: 1e-4 to 1
mixture(range = c(0, 1)),
levels = 10
)
# Tune -------------------------------------------------------------------
tune_results <- tune_grid(
logReg_workflow,
resamples = amazon_folds,
grid = lambda_grid,
metrics = metric_set(roc_auc)
)
install.packages(keras3)
install.packages("keras3")
# Tuning Grid -------------------------------------------------------------
lambda_grid <- grid_regular(
penalty(range = c(-4, 0)),  # log10 scale: 1e-4 to 1
mixture(range = c(0, 1)),
levels = 10
)
# Tune -------------------------------------------------------------------
tune_results <- tune_grid(
logReg_workflow,
resamples = amazon_folds,
grid = lambda_grid,
metrics = metric_set(roc_auc)
)
# Select Best Model ------------------------------------------------------
best_params <- select_best(tune_results, "roc_auc")
rlang::last_trace()
# Select Best Model ------------------------------------------------------
best_params <- select_best(tune_results, metric =  "roc_auc")
# Finalize Workflow ------------------------------------------------------
final_wf <- finalize_workflow(logReg_workflow, best_params)
# Fit Final Model on Full Training Data ----------------------------------
final_fit <- final_wf %>%
fit(data = train_data)
# Predict on Test Data ---------------------------------------------------
amazon_predictions <- predict(final_fit,
new_data = test_data,
type = "prob") %>%
select(.pred_1) %>%
rename(ACTION = .pred_1)
# Create Submission File -------------------------------------------------
kaggle_submission <- test_data %>%
select(id) %>%
bind_cols(amazon_predictions)
vroom_write(kaggle_submission, file = "./TargetEncoded_ElasticNet_Preds.csv", delim = ",")
# Cross-validation -------------------------------------------------------
set.seed(123)
amazon_folds <- vfold_cv(train_data, v = 5, strata = ACTION)
# Tuning Grid -------------------------------------------------------------
lambda_grid <- grid_regular(
penalty(range = c(0, 1)),  # log10 scale: 1e-4 to 1
mixture(range = c(0, 1)),
levels = 10
)
# Tune -------------------------------------------------------------------
tune_results <- tune_grid(
logReg_workflow,
resamples = amazon_folds,
grid = lambda_grid,
metrics = metric_set(roc_auc)
)
# Select Best Model ------------------------------------------------------
best_params <- select_best(tune_results, metric =  "roc_auc")
# Finalize Workflow ------------------------------------------------------
final_wf <- finalize_workflow(logReg_workflow, best_params)
# Fit Final Model on Full Training Data ----------------------------------
final_fit <- final_wf %>%
fit(data = train_data)
# Predict on Test Data ---------------------------------------------------
amazon_predictions <- predict(final_fit,
new_data = test_data,
type = "prob") %>%
select(.pred_1) %>%
rename(ACTION = .pred_1)
# Create Submission File -------------------------------------------------
kaggle_submission <- test_data %>%
select(id) %>%
bind_cols(amazon_predictions)
vroom_write(kaggle_submission, file = "./TargetEncoded_ElasticNet_Preds.csv", delim = ",")
my_recipe <- recipe(ACTION ~ ., data = train_data) %>%
step_mutate_at(all_numeric_predictors(), fn = as.factor) %>%
step_other(all_nominal_predictors(), threshold = 0.001) %>%
step_embed(all_nominal_predictors(), outcome = vars(ACTION)) %>%  # <-- target encoding
step_zv(all_predictors())  # remove zero-variance columns
# Model Specification: Penalized Logistic Regression ---------------------
logRegModel <- logistic_reg(
penalty = tune(),  # lambda
mixture = tune()   # alpha
) %>%
set_engine("glmnet") %>%
set_mode("classification")
# Workflow ---------------------------------------------------------------
logReg_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(logRegModel)
# Cross-validation -------------------------------------------------------
set.seed(123)
amazon_folds <- vfold_cv(train_data, v = 5, strata = ACTION)
# Tuning Grid -------------------------------------------------------------
lambda_grid <- grid_regular(
penalty(range = c(-4, 0)),  # log10 scale: 1e-4 to 1
mixture(range = c(0, 1)),
levels = 10
)
# Tune -------------------------------------------------------------------
tune_results <- tune_grid(
logReg_workflow,
resamples = amazon_folds,
grid = lambda_grid,
metrics = metric_set(roc_auc)
)
# Select Best Model ------------------------------------------------------
best_params <- select_best(tune_results, metric =  "roc_auc")
# Finalize Workflow ------------------------------------------------------
final_wf <- finalize_workflow(logReg_workflow, best_params)
# Fit Final Model on Full Training Data ----------------------------------
final_fit <- final_wf %>%
fit(data = train_data)
# Predict on Test Data ---------------------------------------------------
amazon_predictions <- predict(final_fit,
new_data = test_data,
type = "prob") %>%
select(.pred_1) %>%
rename(ACTION = .pred_1)
# Create Submission File -------------------------------------------------
kaggle_submission <- test_data %>%
select(id) %>%
bind_cols(amazon_predictions)
vroom_write(kaggle_submission, file = "./TargetEncoded_ElasticNet_Preds.csv", delim = ",")
View(best_params)
